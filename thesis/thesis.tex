%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%  A small sample UNSW Honours Thesis file.
%  Any questions to Ian Doust i.doust@unsw.edu.au
%
% Edited CSG 11.9.2015, use some of Gery's ideas for front matter; add a conclusion chapter.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%  The first part pulls in a UNSW Thesis class file.  This one is
%  slightly nonstandard and has been set up to do a couple of
%  things automatically
%
 
\documentclass[honours,12pt]{unswthesis}
\linespread{1}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{latexsym,amsmath}
\usepackage{graphicx}
\usepackage{afterpage}
\usepackage{hyperref}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%  The following are some simple LaTeX macros to give some
%  commonly used letters in funny fonts. You may need more or less of
%  these
%
\newcommand{\R}{\mathbb{R}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\F}{\mathbb{F}}
\newcommand{\PP}{\mathbb{P}}
\newcommand{\T}{\mathbb{T}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\B}{\mathfrak{B}}
\newcommand{\BB}{\mathcal{B}}
\newcommand{\M}{\mathfrak{M}}
\newcommand{\X}{\mathfrak{X}}
\newcommand{\Y}{\mathfrak{Y}}
\newcommand{\CC}{\mathcal{C}}
\newcommand{\E}{\mathbb{E}}
\newcommand{\cP}{\mathcal{P}}
\newcommand{\cS}{\mathcal{S}}
\newcommand{\A}{\mathcal{A}}
\newcommand{\ZZ}{\mathcal{Z}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% The following are much more esoteric commands that I have left in
% so that this file still processes. Use or delete as you see fit
%
\newcommand{\bv}[1]{\mbox{BV($#1$)}}
\newcommand{\comb}[2]{\left(\!\!\!\begin{array}{c}#1\\#2\end{array}\!\!\!\right)
}
\newcommand{\Lat}{{\rm Lat}}
\newcommand{\var}{\mathop{\rm var}}
\newcommand{\Pt}{{\mathcal P}}
\def\tr(#1){{\rm trace}(#1)}
\def\Exp(#1){{\mathbb E}(#1)}
\def\Exps(#1){{\mathbb E}\sparen(#1)}
\newcommand{\floor}[1]{\left\lfloor #1 \right\rfloor}
\newcommand{\ceil}[1]{\left\lceil #1 \right\rceil}
\newcommand{\hatt}[1]{\widehat #1}
\newcommand{\modeq}[3]{#1 \equiv #2 \,(\text{mod}\, #3)}
\newcommand{\rmod}{\,\mathrm{mod}\,}
\newcommand{\p}{\hphantom{+}}
\newcommand{\vect}[1]{\mbox{\boldmath $ #1 $}}
\newcommand{\reff}[2]{\ref{#1}.\ref{#2}}
\newcommand{\psum}[2]{\sum_{#1}^{#2}\!\!\!'\,\,}
\newcommand{\bin}[2]{\left( \begin{array}{@{}c@{}}
				#1 \\ #2
			\end{array}\right)	}
%
%  Macros - some of these are in plain TeX (gasp!)
%
\newcommand{\be}{($\beta$)}
\newcommand{\eqp}{\mathrel{{=}_p}}
\newcommand{\ltp}{\mathrel{{\prec}_p}}
\newcommand{\lep}{\mathrel{{\preceq}_p}}
\def\brack#1{\left \{ #1 \right \}}
\def\bul{$\bullet$\ }
\def\cl{{\rm cl}}
\let\del=\partial
\def\enditem{\par\smallskip\noindent}
\def\implies{\Rightarrow}
\def\inpr#1,#2{\t \hbox{\langle #1 , #2 \rangle} \t}
\def\ip<#1,#2>{\langle #1,#2 \rangle}
\def\lp{\ell^p}
\def\maxb#1{\max \brack{#1}}
\def\minb#1{\min \brack{#1}}
\def\mod#1{\left \vert #1 \right \vert}
\def\norm#1{\left \Vert #1 \right \Vert}
\def\paren(#1){\left( #1 \right)}
\def\qed{\hfill \hbox{$\Box$} \smallskip}
\def\sbrack#1{\Bigl \{ #1 \Bigr \} }
\def\ssbrack#1{ \{ #1 \} }
\def\smod#1{\Bigl \vert #1 \Bigr \vert}
\def\smmod#1{\bigl \vert #1 \bigr \vert}
\def\ssmod#1{\vert #1 \vert}
\def\sspmod#1{\vert\, #1 \, \vert}
\def\snorm#1{\Bigl \Vert #1 \Bigr \Vert}
\def\ssnorm#1{\Vert #1 \Vert}
\def\sparen(#1){\Bigl ( #1 \Bigr )}

\newcommand\blankpage{%
    \null
    \thispagestyle{empty}%
    \addtocounter{page}{-1}%
    \newpage}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% These environments allow you to get nice numbered headings
%  for your Theorems, Definitions etc.  
%
%  Environments
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{conjecture}[theorem]{Conjecture}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{example}[theorem]{Example}
\newtheorem{remark}[theorem]{Remark}
\newtheorem{question}[theorem]{Question}
\newtheorem{notation}[theorem]{Notation}
\numberwithin{equation}{section}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%  If you've got some funny special words that LaTeX might not
% hyphenate properly, you can give it a helping hand:
%
\hyphenation{Mar-cin-kie-wicz Rade-macher}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 
% OK...Now we get to some actual input.  The first part sets up
% the title etc that will appear on the front page
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\title{Surrogated Assisted Bayesian Neural Network for Geological Models}

\authornameonly{Sean Luo}

\author{\Authornameonly\\{\bigskip}Supervisors: Rohitash Chandra, Richard Scalzo}

\copyrightfalse
\figurespagefalse
\tablespagefalse

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%  And now the document begins
%  The \beforepreface and \afterpreface commands puts the
%  contents page etc in
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

\beforepreface

\afterpage{\blankpage}

% plagiarism

\prefacesection{Plagiarism statement}

\vskip 10pc \noindent I declare that this thesis is my
own work, except where acknowledged, and has not been submitted for
academic credit elsewhere. 

\vskip 2pc  \noindent I acknowledge that the assessor of this
thesis may, for the purpose of assessing it:
\begin{itemize}
\item Reproduce it and provide a copy to another member of the University; and/or,
\item Communicate a copy of it to a plagiarism checking service (which may then retain a copy of it on its database for the purpose of future plagiarism checking).
\end{itemize}

\vskip 2pc \noindent I certify that I have read and understood the University Rules in
respect of Student Academic Misconduct, and am aware of any potential plagiarism penalties which may 
apply.\vspace{24pt}

\vskip 2pc \noindent By signing 
this declaration I am
agreeing to the statements and conditions above.
\vskip 2pc \noindent
Signed: \rule{7cm}{0.25pt} \hfill Date: \rule{4cm}{0.25pt} \newline
\vskip 1pc

\afterpage{\blankpage}

% Acknowledgements are optional


\prefacesection{Acknowledgements}

{\bigskip}By far the greatest thanks must go to my supervisor for
the guidance, care and support they provided. 
 
{\bigskip} Thanks to my family for supporting me to advance in higher education.

{\bigskip\noindent} Thanks go to Fred Flintstone and Robert Taggart for allowing this thesis
style to be shamelessly copied.

{\bigskip\bigskip\bigskip\noindent} Sean Luo, Day Month Year.

\afterpage{\blankpage}

% Abstract

\prefacesection{Abstract}

Bayesian learning methods natively offer insights into dependencies between parameters and posterior probability density estimation in complex systems. Markov Chain Monte Carlo methods compare to variational inference methods offers an asymptotically exact approximation to the posterior. However it suffers from exponetially high computational cost in multimodal high dimensional distributions due to high rejection rate from proposal distributions such as Langevin Dynamic or network architecture. This thesis propose to sample from a surrogate proposal distribution approximated by a Generative Adversarial Network trained from previously accepted proposals from parallelized tempered training such that it increases the acceptance rate and avoid the expensive forward pass that is required for Langevin Dynamics. 

The results hopefully don't prove to be inconclusive.

Finally this method is demonstrated on a large geological model on radar data. 


\afterpage{\blankpage}


\afterpreface

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% Now we can start on the first chapter
% Within chapters we have sections, subsections and so forth
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\afterpage{\blankpage}

\chapter{Introduction (Currently a collection of messy notes)}\label{intro}

Application of bayesian methods

In the past decade there has being some progression in the field of bayesian deep learning. Bayesian deep learning offers an intrinsic way to ensemble models that helps to quantify the posterior uncertainty in model parameters and prediction. Applying tradition bayesian inference techniques such as Monte Carlo sampling in deep neural networks have multiple challenges, mainly revolving around computational expenses due to the evaluation speed of large dataset, exponentially increasing rejection rate in MCMC sampler as the parameter space dimensions grows with large model, difficulty to evaluate uncertainty in realtime data, efficient proposal convergence and others. Variational bayesian inference methods are faster than sampling, but it does not offer an exact approximation of the target distribution. 


%% other challenges to be include via further paper reading

\noindent Ideas explored: 

Pure Bayesian:

\begin{enumerate}
\item Using stochastic mini batches with Langevin dynamic by Welling et al \cite{StochGradLangevin}.

\item Using langevin dynamic Dynamic as proposal to predict time series by chandra et al \cite{Chandra2017BayesianNL} 

\item Using parallel tempering to speed up exploration and exploitation by chandra \cite{LDPTBNN}

\item Using surrogate models to simulate the posterior likelihood $p(D|\theta)$ to speed up evaluation, by chandra. \cite{SAPTBNN}

\item Surrogate models are selected from variantional inference category, including, GAN, VAE, and Normaling Flow.

\item Train a WGAN to approximate the joint prior distribution of parameter and state, and sample from latent space instead. This is useful when the domain has high dimension of state and input parameters that each have different prior distributions. \cite{mucke2021MCWGAN}. \href{https://www.youtube.com/watch?v=NpgL3Rve2Rg}{youtube video of paper presentation}

\item Using GAN to learn target optimization function's landscape, specifically around mode/modes (unsure) optimum. \cite{OPTGAN2021}
\end{enumerate}

Modification to frequentist models that turns into bayesian:
\begin{enumerate}
\item Using dropout as intrinsic ensemble (bayesian?).

\item Using stochastic weight averaging withe gaussian noise (SWAG) for bayesian model averaging by approximating a normal weight posterior initialized on a pretrained solution. Bayesian model averaging in general prevents overfitting and overconfidence  - Maddox et al \cite{NEURIPS2019_SWAG}
\end{enumerate}


Other assumptions and constraints
\begin{enumerate}
\item weight decay as normal prior on weights
\end{enumerate}
    
\section{Generative Models}

The target loss function for generative model in continuous case (we care for continuous case only as we plan to use it to generate the weights) in unsupervised setting is $L(D) \approxeq \frac{1}{N}\sum_{i=1}^N - \log(p_\theta(\tilde{x}^{(i)}))+c$. Where $\tilde{x}^{(i)} = x^{i}+u$ with $u\sim U(0,a)$ and $c=-M\times \log{a}$, $a$ is dependent on data discretization and $M$ is the dimension of $x$. This loss function encourages the network to learn to distribute data across the domain of the standard normal distribution. When there is an underlying distribution to approximate, we need to utilizes distance/divergence measures in loss function to have convergent distribution.

VAE is a shrinkage training model that has two shrinker that trains to a latent space of mean and variance of normal distribution.
from the two latent vector it then trains to simulate a proper input.

GAN have discriminator and generator, generator samples from standard normal and maps it via a network to output space, discriminator compare the overall generated result to dataset. The training is conducted via a maximizing loss for discriminator and minimizing loss on generator.

Normalizing Flow is composed of multiple inversible layers that helps to provide a tractable posterior likelihood on weights. Due to the decomposition of Jacobian matrix during gradient calculation, there is a significant reduction in memory requirements. Specifically the GLOW model proposed by OpenAI \cite{openai2018glow} uses 1x1 convolution to simulate channel switching to boost training performance. Another paper from USTC improves upon this by using matrix exponentials (no idea what it means at the moment)

In flow and autoencoder we are dealing with distributions directly in the latent space (flow is autoencoder with only one network) and Arjovsky (NYU) \cite{PMLR2017_WGAN} et al proposed in 2017 to simulate the Wasserstein distance (in general Earth Mover Distance) instead as a loss measure when training GAN.(may be it can be applied to VAE or NF? Or maybe it already is, base on how I see the implementation). 

It is stated that divergence measures such as Jensen or KL fails to pickup the low dimensional manifold of a lot of problems' distributions (Q: are the distribution of weights of DNN parameters supported by low dimensional manifolds?), further in practice, other measures when training GAN produces in saturated discriminator that fails to provided any sensible gradient afterwards, that leads to mode collapse. WGAN resolves this as further training of critic/(score based discriminator instead of class based discriminator) still provides reasonable gradient. WGAN's weakness include failure when using momentum based optimizer (use RMSProp instead), and the clamping of hyperparameters to maintain lipschitz (what does this mean?) seems to be troublesome as it is problem specific. This is addressed by Gulrajani \cite{NIPS2017_WGAN-GP} using gradient penalty normalisation to replace the clipping that allows the loss to be normally distributed instead of bernoulli distrbuted at the two clipping points. This paper also states that WGAN has comparable epoch performance to WCGAN while offering better stability, the caveat is a slower wallclock time. 

More info here \href{https://lilianweng.github.io/lil-log/2017/08/20/from-GAN-to-WGAN.html}{GAN vs WGAN}

short read on improved \href{https://towardsdatascience.com/demystified-wasserstein-gan-with-gradient-penalty-ba5e9b905ead}{WGAN - Gradient Penalty}

\section{low dimensional manifold}
(Imagine your patterned bedsheets. They've got a nice plaid grid look to them, very easy to predict what the next few centimeters of material look like.

Now imagine someone tied them in a knot, tore them a little, balled them up, and made them a crumpled mess, then handed them to you. Now if you were to look at the plaid pattern, it would be very difficult to discern how the pattern is, or predict what will be the color of any point of the arbitrary 3D ball of mess you've got. But if you untangled it, you could clearly see the pattern again.

The data is a bunch of colors in an arbitrary 3D ball of mess with very difficult to discern patterns. But the data lies on a low dimensional manifold (the 2D bedsheet). If you could figure out the manifold (flatten the bedsheet), the data will be easy to model.)  $explaination\ on\ reddit$

(stil have problem understanding the math behind it, but implementation wise i think it just removes the bounded final activation and uses the score as a loss) 

\section{Markov Chain Monte Carlo}

\section{Langevin Dynamics}
In standard LD or 1 Leap frog step of Hamilton Dynamics, there is 1 distinctive forward+backward pass in a leap frog step:

\begin{enumerate}
    \item w\_last forward (for posterior likelihood $p(data|w\_last)$)
    \item w\_last backward (for proposal distribution mean w\_last\_bar,$w\_star \sim N(w\_last\_bar,\sigma)$) 
    \item w\_star forward (for posterior likelihood $p(data|w\_star)$)
    \item w\_star backward (for proposal distribution mean w\_star\_bar,$w\_last \sim N(w\_star\_bar,\sigma)$) 
\end{enumerate}

The empirical results agrees thats the time complexity with respect to epoch of frequentist training and langevin proposal is identical, but langevin is about 3-4 times slower in my impleentation. The suspected reason is the heavy cost of weight replacement/ duplication and copy for statistic analysis purpose. I need to confirm by how much this can be optimized. 

w\_last are reused from last iteration.

By using a surrogate model to approximate the posterior likelihood $p(data|w_star)$ we replaced step 3's forward pass.

\section{Proposal}
Now we propose to replace step 4's backward pass with a GAN that generates the weights.

The believed benefits includes:
\begin{enumerate}
\item faster evaluation.
\end{enumerate}

For this GAN to be benificial, it has several constraints: 
\begin{enumerate}
    \item shallower than original network.
    \item approximates the full posterior $p(w|data)$.
\end{enumerate}

\section{Potential Challenges}
overfitting of GAN that leads to no escape of local optimum during training or heatup. 

Potential Solutions:
\begin{itemize}
\item use exploration/ exploitation 
\item maybe solvable with parallel tempering with different loss penalty in wgan?)
\end{itemize}

Solving the detailed balance condition of using GAN. because of generating from normal. we need to consider the probability transformation.
Tasks and potential solutions:
\begin{itemize}
\item use flow based GAN or flow
\item calculate the invertible functions and the respective post transform distribution of GAN
\item ignore?
\end{itemize}


\section{Random Ideas}
Multiple GANs, each for different module/layers of network such that it works for larger network like resnet50.

Federated learning - consider each parallel process to have its own minibatch as localized individual data.

Few shot learning - consider a potentially limited amount of accepted samples for training. 


\section{ Notes:}

Swag : approximates local loss distribution (posterior?) using standard normal momentum distribution.
Propose -> Accept Reject: replacing forward pass for proposal 
Surrogate by Chandra et al: evaluate proposal and spit out its posterior likelihood
    i.e. 
    
    $min(1, pi(w*|x)/pi(wi|x) *  q(wi|w*)/q(w*|wi) )$
    
    $min(1, p(x|w*)/p(x|wi) * p(w*|x)/p(wi|x) *  q(wi|w*)/q(w*|wi) )$

    $p(w|x)$ and $q(wi|w*)$ are both easy to compute, the first is a loss, the second is proposal distribution (using tractable distribution like normal that s easy to evaluate)    
    $p(x|w)$ requires forward pass, so we evaluate it using surrogate


\noindent $https://www.lpsm.paris/pageperso/merle/slides_3.1.TV.pdf$ stuff for distance understanding

list to read
\href{https://jmlr.org/papers/volume22/20-1009/20-1009.pdf}{Tractable Approximate Gaussian Inference for
Bayesian Neural Networks
}

\href{https://arxiv.org/pdf/1701.04722.pdf}{Adversarial Variational Bayes:
Unifying Variational Autoencoders and Generative Adversarial Networks}

\href{https://towardsdatascience.com/gans-vs-autoencoders-comparison-of-deep-generative-models-985cf15936ea}{GAN vs VAE}

\href{https://pdf.sciencedirectassets.com/271597/1-s2.0-S0925231221X00409/1-s2.0-S0925231221015319/main.pdf?X-Amz-Security-Token=IQoJb3JpZ2luX2VjEAsaCXVzLWVhc3QtMSJGMEQCIFyD6EVhq7gdc13HAw8Qa2abqSEg7RfyW64DmMVAwR%2FAAiAx%2FqYNhfvEXwgQS08r%2FMhhr5VEr%2Be%2BKQ7Nbt9dBYn1iir6AwgjEAQaDDA1OTAwMzU0Njg2NSIMzSUp5Xe14ZtAoyoUKtcD5V8UPCBeS1sryr6y2PzuwXdsx%2FBvmdgsnfgRx1Acrgomb7ZC%2BVpRecYAvucvzsgbXwr4%2FY23IWXOjQVvqaIcF9d6%2F3VF5lJjfBtqyUDoUAZ6fMfSVsgKbMRkbIK%2BUaZot4%2BXfz7LLN3HZla8oHd2sTktGlGF8x4e9UR2PONy%2FZt%2B8Le6H%2FpmTQOEChAS5I23%2Bw0g%2BbW%2B%2FMIOpbdP4tGzrxVpJX4swn1N5QW4SIVF1abKsksuJPt%2FAGLYy%2BzlTEGZ55ycsE0DO3HIQHzRcQcO0MCYd0GcP8sNOmRCk3Jay5KLK%2FPdw0xHow7982Mra1vNMPHgcNPESFshdfg3ukTsqBWWi6AsbEiYJwJDbO1CHpZ4WGllcAvKc91KyLqQE6XUSLzJUCykxTtb1rvjq9ypjki44bdW2ROmKJ%2BymoRnGspYm8U%2FweObZTTKA5LygERVcMPMXLutBWzdSJxvE2DoRgTx5gUpkEpOblBl4QYSwGRFfy1RwxilaNC82XhmeEPUUySfONoSD%2BdRZJk4gtNUjrBJKTtXe7PK8UrnhLybytQ%2BBZTZEl7iU5yb1Zc5jtiGinqiB3FNJ%2BMadk3%2B5ZtfRK2E%2BI5ETcjD6uUYt44KY4kx93sSt%2BAMMNXO844GOqYBLuihn5E46ZnGuLqmP2PzNJSAQ%2F%2Fx6X4SDKC8iS2%2FUaj7e5GPNb69qrcYy%2BnYMmk1XyXxk%2FBmpBj7oKIaS3Xu1GvczXn1i1keem794sv93urWnxC7hYa5Rlx9S2cLqOM9mcNsq1xy6R7lKu2T2of2NvbRYDIjIN1BVAHkr0BWiGSL5L4bFyeJwVgfajomw31LAznCz5G7Arbl3L8EssueNZ2DjR7LVw%3D%3D&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20220111T025152Z&X-Amz-SignedHeaders=host&X-Amz-Expires=300&X-Amz-Credential=ASIAQ3PHCVTYWCQOVEXF%2F20220111%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Signature=63ecad95ada9138a0f14d0c02a0a2f2b564d4ca6a5d6e7e02d06e8a7667310c1&hash=e5ac045fcf223511dbac539722bc02c21c35d61165b6e09cd3e194252b56c49e&host=68042c943591013ac2b2430a89b270f6af2c76d8dfd086a07176afe7c76c2c61&pii=S0925231221015319&tid=spdf-4e567811-c9bc-4491-a143-d0a95da3d0eb&sid=d01637fd29bfb242294978015ea29ea8700bgxrqa&type=client#page=1&zoom=100,0,0}{Distributed Bayesian optimisation framework for deep neuroevolution}


\href{https://icml.cc/virtual/2020/poster/6640}{Bridging the Gap Between f-GANs and Wasserstein GANs}
\href{https://icml.cc/virtual/2020/poster/5871}{Stronger and Faster Wasserstein Adversarial Attacks}

\href{https://icml.cc/virtual/2020/poster/6028}{Modulating Surrogates for Bayesian Optimization}

\href{https://github.com/ermongroup/markov-chain-gan}{GENERATIVE ADVERSARIAL LEARNING
OF MARKOV CHAINS
}

\href{google search}{ on the quantitative analysis of decoder based generative models}

\noindent Packages of interest include pymc, pyro, pytorch, (maybe  sydney-machine-learning/pingala?)

\section{Proposal}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Sampling}\label{samp}





%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Method}\label{meth}




%%%%%%%%%%%%%%%%
\chapter{Experiment}\label{expe}


\chapter{Analysis}\label{anal}


\chapter{Discussion}\label{disc}

\chapter{Conclusion}\label{conc}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\clearpage

\addcontentsline{toc}{chapter}{References}

% \LaTeX{} \cite{latex2e} is a set of macros built atop \TeX{} \cite{texbook}.
\bibliographystyle{unsrt} % We choose the "plain" reference style
\bibliography{refs} % Entries are in the refs.bib file

\end{document}





