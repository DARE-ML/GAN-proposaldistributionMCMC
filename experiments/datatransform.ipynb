{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b521b1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "from Code.transform import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86ed75bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ta': [<function Code.transform.<lambda>(d)>,\n",
       "  <function Code.transform.<lambda>(o, a)>],\n",
       " 'ua': [<function Code.transform.<lambda>(d)>,\n",
       "  <function Code.transform.<lambda>(o, a)>],\n",
       " 'va': [<function Code.transform.<lambda>(d)>,\n",
       "  <function Code.transform.<lambda>(o, a)>],\n",
       " 'wap': [<function Code.transform.<lambda>(d)>,\n",
       "  <function Code.transform.<lambda>(o, a)>],\n",
       " 'hus': [<function Code.transform.<lambda>(d)>,\n",
       "  <function Code.transform.<lambda>(o, a)>],\n",
       " 'zeta': [<function Code.transform.<lambda>(d)>,\n",
       "  <function Code.transform.<lambda>(o, a)>],\n",
       " 'zg': [<function Code.transform.<lambda>(d)>,\n",
       "  <function Code.transform.<lambda>(o, a)>],\n",
       " 'd': [<function Code.transform.<lambda>(d)>,\n",
       "  <function Code.transform.<lambda>(o, a)>],\n",
       " 'ps': [<function Code.transform.<lambda>(d)>,\n",
       "  <function Code.transform.<lambda>(o, a)>]}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f709ec46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "with h5py.File('./data/11y1burn6hres45mstep_mini/chan81_ncdf4.nc', 'a') as raw:\n",
    "    print([k for k in raw['Transformed'].attrs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "55949791",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reached ta 0\n",
      "Done  ta 0 seconds: 30 finished: Sun Jun 26 15:05:42 2022\n",
      "reached ta 1\n",
      "Done  ta 1 seconds: 33 finished: Sun Jun 26 15:06:16 2022\n",
      "reached ta 2\n",
      "Done  ta 2 seconds: 24 finished: Sun Jun 26 15:06:40 2022\n",
      "reached ta 3\n",
      "Done  ta 3 seconds: 25 finished: Sun Jun 26 15:07:06 2022\n",
      "reached ta 4\n",
      "Done  ta 4 seconds: 26 finished: Sun Jun 26 15:07:32 2022\n",
      "reached ta 5\n",
      "Done  ta 5 seconds: 27 finished: Sun Jun 26 15:08:00 2022\n",
      "reached ta 6\n",
      "Done  ta 6 seconds: 28 finished: Sun Jun 26 15:08:28 2022\n",
      "reached ta 7\n",
      "Done  ta 7 seconds: 26 finished: Sun Jun 26 15:08:55 2022\n",
      "reached ta 8\n",
      "Done  ta 8 seconds: 26 finished: Sun Jun 26 15:09:21 2022\n",
      "reached ta 9\n",
      "Done  ta 9 seconds: 28 finished: Sun Jun 26 15:09:50 2022\n",
      "reached ua 0\n",
      "Done  ua 0 seconds: 27 finished: Sun Jun 26 15:10:18 2022\n",
      "reached ua 1\n",
      "Done  ua 1 seconds: 28 finished: Sun Jun 26 15:10:46 2022\n",
      "reached ua 2\n",
      "Done  ua 2 seconds: 28 finished: Sun Jun 26 15:11:15 2022\n",
      "reached ua 3\n",
      "Done  ua 3 seconds: 28 finished: Sun Jun 26 15:11:43 2022\n",
      "reached ua 4\n",
      "Done  ua 4 seconds: 28 finished: Sun Jun 26 15:12:11 2022\n",
      "reached ua 5\n",
      "Done  ua 5 seconds: 28 finished: Sun Jun 26 15:12:39 2022\n",
      "reached ua 6\n",
      "Done  ua 6 seconds: 28 finished: Sun Jun 26 15:13:08 2022\n",
      "reached ua 7\n",
      "Done  ua 7 seconds: 30 finished: Sun Jun 26 15:13:39 2022\n",
      "reached ua 8\n",
      "Done  ua 8 seconds: 33 finished: Sun Jun 26 15:14:12 2022\n",
      "reached ua 9\n",
      "Done  ua 9 seconds: 30 finished: Sun Jun 26 15:14:43 2022\n",
      "reached va 0\n",
      "Done  va 0 seconds: 28 finished: Sun Jun 26 15:15:11 2022\n",
      "reached va 1\n",
      "Done  va 1 seconds: 28 finished: Sun Jun 26 15:15:39 2022\n",
      "reached va 2\n",
      "Done  va 2 seconds: 32 finished: Sun Jun 26 15:16:12 2022\n",
      "reached va 3\n",
      "Done  va 3 seconds: 34 finished: Sun Jun 26 15:16:46 2022\n",
      "reached va 4\n",
      "Done  va 4 seconds: 31 finished: Sun Jun 26 15:17:18 2022\n",
      "reached va 5\n",
      "Done  va 5 seconds: 27 finished: Sun Jun 26 15:17:45 2022\n",
      "reached va 6\n",
      "Done  va 6 seconds: 29 finished: Sun Jun 26 15:18:14 2022\n",
      "reached va 7\n",
      "Done  va 7 seconds: 35 finished: Sun Jun 26 15:18:49 2022\n",
      "reached va 8\n",
      "Done  va 8 seconds: 34 finished: Sun Jun 26 15:19:24 2022\n",
      "reached va 9\n",
      "Done  va 9 seconds: 30 finished: Sun Jun 26 15:19:54 2022\n",
      "reached hus 0\n",
      "Done  hus 0 seconds: 29 finished: Sun Jun 26 15:20:24 2022\n",
      "reached hus 1\n",
      "Done  hus 1 seconds: 29 finished: Sun Jun 26 15:20:53 2022\n",
      "reached hus 2\n",
      "Done  hus 2 seconds: 33 finished: Sun Jun 26 15:21:26 2022\n",
      "reached hus 3\n",
      "Done  hus 3 seconds: 34 finished: Sun Jun 26 15:22:01 2022\n",
      "reached hus 4\n",
      "Done  hus 4 seconds: 31 finished: Sun Jun 26 15:22:33 2022\n",
      "reached hus 5\n",
      "Done  hus 5 seconds: 29 finished: Sun Jun 26 15:23:02 2022\n",
      "reached hus 6\n",
      "Done  hus 6 seconds: 27 finished: Sun Jun 26 15:23:29 2022\n",
      "reached hus 7\n",
      "Done  hus 7 seconds: 31 finished: Sun Jun 26 15:24:01 2022\n",
      "reached hus 8\n",
      "Done  hus 8 seconds: 34 finished: Sun Jun 26 15:24:36 2022\n",
      "reached hus 9\n",
      "Done  hus 9 seconds: 34 finished: Sun Jun 26 15:25:10 2022\n",
      "reached ps 0\n",
      "Done  ps 0 seconds: 17 finished: Sun Jun 26 15:25:33 2022\n",
      "reached wap 0\n",
      "Done  wap 0 seconds: 28 finished: Sun Jun 26 15:26:02 2022\n",
      "reached wap 1\n",
      "Done  wap 1 seconds: 27 finished: Sun Jun 26 15:26:30 2022\n",
      "reached wap 2\n",
      "Done  wap 2 seconds: 32 finished: Sun Jun 26 15:27:02 2022\n",
      "reached wap 3\n",
      "Done  wap 3 seconds: 32 finished: Sun Jun 26 15:27:35 2022\n",
      "reached wap 4\n",
      "Done  wap 4 seconds: 31 finished: Sun Jun 26 15:28:07 2022\n",
      "reached wap 5\n",
      "Done  wap 5 seconds: 29 finished: Sun Jun 26 15:28:36 2022\n",
      "reached wap 6\n",
      "Done  wap 6 seconds: 29 finished: Sun Jun 26 15:29:06 2022\n",
      "reached wap 7\n",
      "Done  wap 7 seconds: 30 finished: Sun Jun 26 15:29:37 2022\n",
      "reached wap 8\n",
      "Done  wap 8 seconds: 39 finished: Sun Jun 26 15:30:16 2022\n",
      "reached wap 9\n",
      "Done  wap 9 seconds: 32 finished: Sun Jun 26 15:30:49 2022\n",
      "reached zeta 0\n",
      "Done  zeta 0 seconds: 29 finished: Sun Jun 26 15:31:19 2022\n",
      "reached zeta 1\n",
      "Done  zeta 1 seconds: 28 finished: Sun Jun 26 15:31:47 2022\n",
      "reached zeta 2\n",
      "Done  zeta 2 seconds: 34 finished: Sun Jun 26 15:32:22 2022\n",
      "reached zeta 3\n",
      "Done  zeta 3 seconds: 34 finished: Sun Jun 26 15:32:56 2022\n",
      "reached zeta 4\n",
      "Done  zeta 4 seconds: 32 finished: Sun Jun 26 15:33:29 2022\n",
      "reached zeta 5\n",
      "Done  zeta 5 seconds: 30 finished: Sun Jun 26 15:33:59 2022\n",
      "reached zeta 6\n",
      "Done  zeta 6 seconds: 29 finished: Sun Jun 26 15:34:28 2022\n",
      "reached zeta 7\n",
      "Done  zeta 7 seconds: 32 finished: Sun Jun 26 15:35:01 2022\n",
      "reached zeta 8\n",
      "Done  zeta 8 seconds: 35 finished: Sun Jun 26 15:35:36 2022\n",
      "reached zeta 9\n",
      "Done  zeta 9 seconds: 34 finished: Sun Jun 26 15:36:11 2022\n",
      "reached d 0\n",
      "Done  d 0 seconds: 30 finished: Sun Jun 26 15:36:41 2022\n",
      "reached d 1\n",
      "Done  d 1 seconds: 30 finished: Sun Jun 26 15:37:12 2022\n",
      "reached d 2\n",
      "Done  d 2 seconds: 33 finished: Sun Jun 26 15:37:45 2022\n",
      "reached d 3\n",
      "Done  d 3 seconds: 33 finished: Sun Jun 26 15:38:18 2022\n",
      "reached d 4\n",
      "Done  d 4 seconds: 30 finished: Sun Jun 26 15:38:49 2022\n",
      "reached d 5\n",
      "Done  d 5 seconds: 28 finished: Sun Jun 26 15:39:18 2022\n",
      "reached d 6\n",
      "Done  d 6 seconds: 30 finished: Sun Jun 26 15:39:48 2022\n",
      "reached d 7\n",
      "Done  d 7 seconds: 34 finished: Sun Jun 26 15:40:22 2022\n",
      "reached d 8\n",
      "Done  d 8 seconds: 40 finished: Sun Jun 26 15:41:02 2022\n",
      "reached d 9\n",
      "Done  d 9 seconds: 34 finished: Sun Jun 26 15:41:37 2022\n",
      "reached zg 0\n",
      "Done  zg 0 seconds: 63 finished: Sun Jun 26 15:42:40 2022\n",
      "reached zg 1\n",
      "Done  zg 1 seconds: 38 finished: Sun Jun 26 15:43:19 2022\n",
      "reached zg 2\n",
      "Done  zg 2 seconds: 38 finished: Sun Jun 26 15:43:57 2022\n",
      "reached zg 3\n",
      "Done  zg 3 seconds: 40 finished: Sun Jun 26 15:44:38 2022\n",
      "reached zg 4\n",
      "Done  zg 4 seconds: 36 finished: Sun Jun 26 15:45:14 2022\n",
      "reached zg 5\n",
      "Done  zg 5 seconds: 32 finished: Sun Jun 26 15:45:47 2022\n",
      "reached zg 6\n",
      "Done  zg 6 seconds: 38 finished: Sun Jun 26 15:46:26 2022\n",
      "reached zg 7\n",
      "Done  zg 7 seconds: 36 finished: Sun Jun 26 15:47:02 2022\n",
      "reached zg 8\n",
      "Done  zg 8 seconds: 31 finished: Sun Jun 26 15:47:34 2022\n",
      "reached zg 9\n",
      "Done  zg 9 seconds: 30 finished: Sun Jun 26 15:48:04 2022\n"
     ]
    }
   ],
   "source": [
    "redo_flag = True\n",
    "from time import time,ctime\n",
    "with h5py.File('./data/11y1burn6hres45mstep_mini/chan81_ncdf4.nc', 'a') as raw:\n",
    "    #with h5py.File('TransformedDS.hdf5','a') as file:\n",
    "    if \"Transformed\" not in raw:\n",
    "        raw.create_dataset(\"Transformed\",(14608,81,32,64),dtype = 'f4')\n",
    "    if redo_flag:\n",
    "        descr = [          \n",
    "             ('ta',  'air_temperature',       '10','130','K'),\n",
    "             ('ua',  'eastward_wind',         '10','131','m s-1'),\n",
    "             ('va',  'northward_wind',        '10','132','m s-1'),\n",
    "             ('hus', 'specific_humidity',     '10','133','kg/kg'),\n",
    "             ('ps',  'surface_air_pressure',  '1 ','134','hPa'),\n",
    "             ('wap',  'vertical_air_velocity', '10','135','Pa s-1'),\n",
    "             ('zeta','atm_relative_vorticity','10','138','s-1'),\n",
    "             ('d',   'divergence of wind',    '10','155','s-1'),\n",
    "             ('zg',  'geopotential_height',   '10','156','m'),\n",
    "        ]\n",
    "        cumlv = 0\n",
    "        transform_time_by_lv = []\n",
    "        for k,_,lv,_,_ in descr:\n",
    "            \n",
    "            d = raw[k]\n",
    "            if k == 'ps':\n",
    "                d = np.expand_dims(d,1)\n",
    "            transform_meta = []\n",
    "            for l in range(int(lv)):\n",
    "                s_time = time()\n",
    "                print(\"reached\",k,l)\n",
    "                transformed, attrs = transforms[k][0](d[:,l,:,:])\n",
    "                transform_meta.append([[k,str(v)] for k,v in attrs.items()])\n",
    "                raw['Transformed'][:,cumlv,:,:] = transformed\n",
    "                cumlv += 1\n",
    "                \n",
    "                e_time = time()\n",
    "                taken = e_time-s_time\n",
    "                transform_time_by_lv.append(taken)\n",
    "                print(\"Done \",k,l,'seconds:',int(taken),\"finished:\",ctime(e_time))\n",
    "            raw['Transformed'].attrs.create(\n",
    "                name = k+\" transformation meta statistic by hPa levels 100 to 1000\",\n",
    "                data = transform_meta\n",
    "            )\n",
    "            \n",
    "        raw['Transformed'].attrs.create(name = \"channels info in order: abbrev, name, levels, puma code, unit\",\n",
    "             data = descr\n",
    "        )\n",
    "        raw['Transformed'].attrs.create(name = \"order of atmospheric level in pressure: from space to surface\",\n",
    "            data = [100,200,300,400,500,600,700,800,900,1000]\n",
    "        )\n",
    "        raw['Transformed'].attrs.create(name = \"dimension info\",\n",
    "            data = [\n",
    "                '14608 timesteps of 6h, date since 0002-01-01 00:00:00',\n",
    "                '81 channels of features',\n",
    "                '32 latitudes',\n",
    "                '64 longitudes',\n",
    "            ]\n",
    "        )\n",
    "    if \"Latitude_map\" not in raw:\n",
    "        raw.create_dataset(\"Latitude_map\",(32,64),dtype = 'f4')\n",
    "        raw['Latitude_map'][:] = np.tile(np.linspace(1,-1,32),(64,1)).T "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "19d659aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "('channels info in order: abbrev, name, levels, puma code, unit', array([['ta', 'air_temperature', '10', '130', 'K'],\n",
      "       ['ua', 'eastward_wind', '10', '131', 'm s-1'],\n",
      "       ['va', 'northward_wind', '10', '132', 'm s-1'],\n",
      "       ['hus', 'specific_humidity', '10', '133', 'kg/kg'],\n",
      "       ['ps', 'surface_air_pressure', '1 ', '134', 'hPa'],\n",
      "       ['wap', 'vertical_air_velocity', '10', '135', 'Pa s-1'],\n",
      "       ['zeta', 'atm_relative_vorticity', '10', '138', 's-1'],\n",
      "       ['d', 'divergence of wind', '10', '155', 's-1'],\n",
      "       ['zg', 'geopotential_height', '10', '156', 'm']], dtype=object))\n",
      "----------\n",
      "('d transformation meta statistic by hPa levels 100 to 1000', array([[['mean', '-7.6633615e-09'],\n",
      "        ['std', '1.908378e-06']],\n",
      "\n",
      "       [['mean', '-7.977629e-09'],\n",
      "        ['std', '3.5284688e-06']],\n",
      "\n",
      "       [['mean', '-1.5144217e-08'],\n",
      "        ['std', '2.8961429e-06']],\n",
      "\n",
      "       [['mean', '-1.27441835e-08'],\n",
      "        ['std', '2.016561e-06']],\n",
      "\n",
      "       [['mean', '-6.186638e-09'],\n",
      "        ['std', '1.5859464e-06']],\n",
      "\n",
      "       [['mean', '-3.0415004e-09'],\n",
      "        ['std', '1.6727196e-06']],\n",
      "\n",
      "       [['mean', '1.2208674e-09'],\n",
      "        ['std', '3.0478425e-06']],\n",
      "\n",
      "       [['mean', '7.2235785e-08'],\n",
      "        ['std', '3.947061e-06']],\n",
      "\n",
      "       [['mean', '1.4475536e-07'],\n",
      "        ['std', '5.244685e-06']],\n",
      "\n",
      "       [['mean', '2.3670181e-07'],\n",
      "        ['std', '8.334231e-06']]], dtype=object))\n",
      "----------\n",
      "('dimension info', array(['14608 timesteps of 6h, date since 0002-01-01 00:00:00',\n",
      "       '81 channels of features', '32 latitudes', '64 longitudes'],\n",
      "      dtype=object))\n",
      "----------\n",
      "('hus transformation meta statistic by hPa levels 100 to 1000', array([[['max', '7.835741e-05'],\n",
      "        ['min', '0.0'],\n",
      "        ['mean', '0.45562252'],\n",
      "        ['std', '0.19125436']],\n",
      "\n",
      "       [['max', '0.00078203937'],\n",
      "        ['min', '0.0'],\n",
      "        ['mean', '0.3789023'],\n",
      "        ['std', '0.17761292']],\n",
      "\n",
      "       [['max', '0.0028155646'],\n",
      "        ['min', '0.0'],\n",
      "        ['mean', '0.37942344'],\n",
      "        ['std', '0.20995314']],\n",
      "\n",
      "       [['max', '0.005483589'],\n",
      "        ['min', '0.0'],\n",
      "        ['mean', '0.40361342'],\n",
      "        ['std', '0.21185067']],\n",
      "\n",
      "       [['max', '0.008127952'],\n",
      "        ['min', '0.0'],\n",
      "        ['mean', '0.43386853'],\n",
      "        ['std', '0.21061547']],\n",
      "\n",
      "       [['max', '0.01273786'],\n",
      "        ['min', '0.0'],\n",
      "        ['mean', '0.43469337'],\n",
      "        ['std', '0.20224833']],\n",
      "\n",
      "       [['max', '0.014478905'],\n",
      "        ['min', '0.0'],\n",
      "        ['mean', '0.46290955'],\n",
      "        ['std', '0.2159592']],\n",
      "\n",
      "       [['max', '0.019041419'],\n",
      "        ['min', '0.0'],\n",
      "        ['mean', '0.46311903'],\n",
      "        ['std', '0.21866012']],\n",
      "\n",
      "       [['max', '0.022751579'],\n",
      "        ['min', '0.0'],\n",
      "        ['mean', '0.50961655'],\n",
      "        ['std', '0.24090211']],\n",
      "\n",
      "       [['max', '0.027509468'],\n",
      "        ['min', '0.0'],\n",
      "        ['mean', '0.5069783'],\n",
      "        ['std', '0.25253937']]], dtype=object))\n",
      "----------\n",
      "('order of atmospheric level in pressure: from space to surface', array([ 100,  200,  300,  400,  500,  600,  700,  800,  900, 1000]))\n",
      "----------\n",
      "('ps transformation meta statistic by hPa levels 100 to 1000', array([[['mean', '970.861'],\n",
      "        ['std', '85.82358']]], dtype=object))\n",
      "----------\n",
      "('ta transformation meta statistic by hPa levels 100 to 1000', array([[['max', '-188.2459'],\n",
      "        ['min', '-247.83406'],\n",
      "        ['mean', '0.46743032'],\n",
      "        ['std', '0.05810476']],\n",
      "\n",
      "       [['max', '-195.41347'],\n",
      "        ['min', '-241.07788'],\n",
      "        ['mean', '0.3878469'],\n",
      "        ['std', '0.10331212']],\n",
      "\n",
      "       [['max', '-202.33234'],\n",
      "        ['min', '-256.29614'],\n",
      "        ['mean', '0.3796616'],\n",
      "        ['std', '0.15858287']],\n",
      "\n",
      "       [['max', '-208.82594'],\n",
      "        ['min', '-267.5992'],\n",
      "        ['mean', '0.35230532'],\n",
      "        ['std', '0.1717704']],\n",
      "\n",
      "       [['max', '-216.42706'],\n",
      "        ['min', '-276.04227'],\n",
      "        ['mean', '0.33786777'],\n",
      "        ['std', '0.17672153']],\n",
      "\n",
      "       [['max', '-193.34843'],\n",
      "        ['min', '-288.02496'],\n",
      "        ['mean', '0.2672191'],\n",
      "        ['std', '0.12120483']],\n",
      "\n",
      "       [['max', '-198.45227'],\n",
      "        ['min', '-296.64005'],\n",
      "        ['mean', '0.28143576'],\n",
      "        ['std', '0.12002813']],\n",
      "\n",
      "       [['max', '-192.5838'],\n",
      "        ['min', '-307.32614'],\n",
      "        ['mean', '0.28851154'],\n",
      "        ['std', '0.11067494']],\n",
      "\n",
      "       [['max', '-194.69768'],\n",
      "        ['min', '-314.7004'],\n",
      "        ['mean', '0.30037093'],\n",
      "        ['std', '0.11609994']],\n",
      "\n",
      "       [['max', '-190.25734'],\n",
      "        ['min', '-321.07278'],\n",
      "        ['mean', '0.2947825'],\n",
      "        ['std', '0.123032644']]], dtype=object))\n",
      "----------\n",
      "('ua transformation meta statistic by hPa levels 100 to 1000', array([[['max', '88.913605'],\n",
      "        ['min', '-43.164703'],\n",
      "        ['mean', '0.756556'],\n",
      "        ['std', '0.07011185']],\n",
      "\n",
      "       [['max', '99.19586'],\n",
      "        ['min', '-36.641277'],\n",
      "        ['mean', '0.7244769'],\n",
      "        ['std', '0.07884803']],\n",
      "\n",
      "       [['max', '90.89667'],\n",
      "        ['min', '-39.07748'],\n",
      "        ['mean', '0.7371813'],\n",
      "        ['std', '0.069337025']],\n",
      "\n",
      "       [['max', '81.04585'],\n",
      "        ['min', '-37.974064'],\n",
      "        ['mean', '0.739831'],\n",
      "        ['std', '0.06254618']],\n",
      "\n",
      "       [['max', '71.681015'],\n",
      "        ['min', '-34.90141'],\n",
      "        ['mean', '0.73663783'],\n",
      "        ['std', '0.05795998']],\n",
      "\n",
      "       [['max', '62.81885'],\n",
      "        ['min', '-29.762936'],\n",
      "        ['mean', '0.7247517'],\n",
      "        ['std', '0.057120573']],\n",
      "\n",
      "       [['max', '52.07537'],\n",
      "        ['min', '-29.734919'],\n",
      "        ['mean', '0.7412922'],\n",
      "        ['std', '0.05359791']],\n",
      "\n",
      "       [['max', '44.33044'],\n",
      "        ['min', '-32.32322'],\n",
      "        ['mean', '0.76311934'],\n",
      "        ['std', '0.0502028']],\n",
      "\n",
      "       [['max', '46.09784'],\n",
      "        ['min', '-39.285625'],\n",
      "        ['mean', '0.77242947'],\n",
      "        ['std', '0.045649603']],\n",
      "\n",
      "       [['max', '46.647808'],\n",
      "        ['min', '-37.4107'],\n",
      "        ['mean', '0.7575611'],\n",
      "        ['std', '0.04793262']]], dtype=object))\n",
      "----------\n",
      "('va transformation meta statistic by hPa levels 100 to 1000', array([[['mean', '0.015832314'],\n",
      "        ['std', '6.207119']],\n",
      "\n",
      "       [['mean', '0.04217133'],\n",
      "        ['std', '8.91295']],\n",
      "\n",
      "       [['mean', '0.032521486'],\n",
      "        ['std', '9.16292']],\n",
      "\n",
      "       [['mean', '0.014601258'],\n",
      "        ['std', '8.339787']],\n",
      "\n",
      "       [['mean', '0.005122252'],\n",
      "        ['std', '7.2248826']],\n",
      "\n",
      "       [['mean', '-0.007600761'],\n",
      "        ['std', '6.1749487']],\n",
      "\n",
      "       [['mean', '-0.008306277'],\n",
      "        ['std', '5.4684544']],\n",
      "\n",
      "       [['mean', '0.13351862'],\n",
      "        ['std', '5.2004485']],\n",
      "\n",
      "       [['mean', '0.22678341'],\n",
      "        ['std', '5.734838']],\n",
      "\n",
      "       [['mean', '0.13163953'],\n",
      "        ['std', '6.405264']]], dtype=object))\n",
      "----------\n",
      "('wap transformation meta statistic by hPa levels 100 to 1000', array([[['mean', '5.27893e-07'],\n",
      "        ['std', '9.6325115e-05']],\n",
      "\n",
      "       [['mean', '1.3936054e-06'],\n",
      "        ['std', '0.0002897872']],\n",
      "\n",
      "       [['mean', '1.7947309e-06'],\n",
      "        ['std', '0.0005192596']],\n",
      "\n",
      "       [['mean', '2.9491607e-06'],\n",
      "        ['std', '0.0006657523']],\n",
      "\n",
      "       [['mean', '4.4881963e-06'],\n",
      "        ['std', '0.0007391037']],\n",
      "\n",
      "       [['mean', '5.6430836e-06'],\n",
      "        ['std', '0.0007641022']],\n",
      "\n",
      "       [['mean', '3.933376e-05'],\n",
      "        ['std', '0.0008025138']],\n",
      "\n",
      "       [['mean', '7.341491e-05'],\n",
      "        ['std', '0.00082058244']],\n",
      "\n",
      "       [['mean', '9.7395576e-05'],\n",
      "        ['std', '0.00079585996']],\n",
      "\n",
      "       [['mean', '7.6670854e-05'],\n",
      "        ['std', '0.0007426737']]], dtype=object))\n",
      "----------\n",
      "('zeta transformation meta statistic by hPa levels 100 to 1000', array([[['mean', '-3.145334e-07'],\n",
      "        ['std', '1.745598e-05']],\n",
      "\n",
      "       [['mean', '-3.0833422e-07'],\n",
      "        ['std', '2.3862929e-05']],\n",
      "\n",
      "       [['mean', '-2.9018946e-07'],\n",
      "        ['std', '2.5004028e-05']],\n",
      "\n",
      "       [['mean', '-2.9260949e-07'],\n",
      "        ['std', '2.3076424e-05']],\n",
      "\n",
      "       [['mean', '-2.67496e-07'],\n",
      "        ['std', '2.0064612e-05']],\n",
      "\n",
      "       [['mean', '-2.3199075e-07'],\n",
      "        ['std', '1.7125229e-05']],\n",
      "\n",
      "       [['mean', '-2.2488427e-07'],\n",
      "        ['std', '1.5016925e-05']],\n",
      "\n",
      "       [['mean', '-1.7196759e-07'],\n",
      "        ['std', '1.3965332e-05']],\n",
      "\n",
      "       [['mean', '-1.0741275e-07'],\n",
      "        ['std', '1.4976271e-05']],\n",
      "\n",
      "       [['mean', '-6.552049e-08'],\n",
      "        ['std', '1.5186481e-05']]], dtype=object))\n",
      "----------\n",
      "('zg transformation meta statistic by hPa levels 100 to 1000', array([[['max', '-14359.511'],\n",
      "        ['min', '-17471.133'],\n",
      "        ['mean', '-1.2807511'],\n",
      "        ['std', '0.7580542']],\n",
      "\n",
      "       [['max', '-10214.955'],\n",
      "        ['min', '-12876.108'],\n",
      "        ['mean', '-1.2354312'],\n",
      "        ['std', '0.8474551']],\n",
      "\n",
      "       [['max', '-7714.497'],\n",
      "        ['min', '-9929.652'],\n",
      "        ['mean', '-1.3401688'],\n",
      "        ['std', '0.92808336']],\n",
      "\n",
      "       [['max', '-5881.9487'],\n",
      "        ['min', '-7731.693'],\n",
      "        ['mean', '-1.3814754'],\n",
      "        ['std', '0.8915715']],\n",
      "\n",
      "       [['max', '-4415.772'],\n",
      "        ['min', '-6004.3296'],\n",
      "        ['mean', '-1.2922299'],\n",
      "        ['std', '0.7244291']],\n",
      "\n",
      "       [['max', '-3186.3289'],\n",
      "        ['min', '-4550.1753'],\n",
      "        ['mean', '-1.3385396'],\n",
      "        ['std', '0.6820713']],\n",
      "\n",
      "       [['max', '-2136.8638'],\n",
      "        ['min', '-3285.0864'],\n",
      "        ['mean', '-1.3304738'],\n",
      "        ['std', '0.5989134']],\n",
      "\n",
      "       [['max', '-1174.8916'],\n",
      "        ['min', '-2209.7646'],\n",
      "        ['mean', '-1.2007658'],\n",
      "        ['std', '0.4234517']],\n",
      "\n",
      "       [['max', '-265.09467'],\n",
      "        ['min', '-1271.471'],\n",
      "        ['mean', '-1.11394'],\n",
      "        ['std', '0.29069468']],\n",
      "\n",
      "       [['max', '566.1494'],\n",
      "        ['min', '-478.50955'],\n",
      "        ['mean', '-0.97446865'],\n",
      "        ['std', '0.2212585']]], dtype=object))\n"
     ]
    }
   ],
   "source": [
    "with h5py.File('./data/11y1burn6hres45mstep_mini/chan81_ncdf4.nc', 'r') as raw:\n",
    "    p = [(x,raw['Transformed'].attrs[x]) for x in raw['Transformed'].attrs]\n",
    "    for x in p:\n",
    "        print(\"----------\")\n",
    "        print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "77098ea7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "10.730785846710205\n",
      "done\n",
      "10.60352349281311\n",
      "done\n",
      "11.622409105300903\n",
      "done\n",
      "9.200344562530518\n",
      "done\n",
      "9.19774580001831\n",
      "done\n",
      "9.862178087234497\n",
      "done\n",
      "9.420050144195557\n",
      "done\n",
      "9.16375994682312\n",
      "done\n",
      "8.592950344085693\n",
      "done\n",
      "8.243056535720825\n",
      "done\n",
      "7.619776010513306\n",
      "done\n",
      "7.408547878265381\n",
      "done\n",
      "7.351538896560669\n",
      "done\n",
      "7.387530326843262\n",
      "done\n",
      "7.546397924423218\n",
      "done\n",
      "8.105213642120361\n",
      "done\n",
      "8.722811460494995\n",
      "done\n",
      "10.926365375518799\n",
      "done\n",
      "11.695982217788696\n",
      "done\n",
      "11.005579233169556\n",
      "done\n",
      "11.154638528823853\n",
      "done\n",
      "11.586600542068481\n",
      "done\n",
      "11.579533100128174\n",
      "done\n",
      "11.000366449356079\n",
      "done\n",
      "9.931631326675415\n",
      "done\n",
      "10.529236316680908\n",
      "done\n",
      "9.848751783370972\n",
      "done\n",
      "9.332143545150757\n",
      "done\n",
      "9.692017793655396\n",
      "done\n",
      "10.597437381744385\n",
      "done\n",
      "11.088218927383423\n",
      "done\n",
      "12.266059398651123\n",
      "done\n",
      "10.732178211212158\n",
      "done\n",
      "10.433953523635864\n",
      "done\n",
      "9.615203619003296\n",
      "done\n",
      "9.960506200790405\n",
      "done\n",
      "9.520212411880493\n",
      "done\n",
      "9.409409999847412\n",
      "done\n",
      "8.79636836051941\n",
      "done\n",
      "9.426941871643066\n",
      "done\n",
      "10.606708288192749\n",
      "done\n",
      "10.10573697090149\n",
      "done\n",
      "10.199861764907837\n",
      "done\n",
      "10.309425592422485\n",
      "done\n",
      "11.101177453994751\n",
      "done\n",
      "11.792078495025635\n",
      "done\n",
      "11.662591457366943\n",
      "done\n",
      "11.601491451263428\n",
      "done\n",
      "11.228462934494019\n",
      "done\n",
      "11.22342824935913\n",
      "done\n",
      "10.50500226020813\n",
      "done\n",
      "10.080684900283813\n",
      "done\n",
      "9.9384286403656\n",
      "done\n",
      "9.56583285331726\n",
      "done\n",
      "9.185258388519287\n",
      "done\n",
      "10.68274998664856\n",
      "done\n",
      "9.907145977020264\n",
      "done\n",
      "10.255717277526855\n",
      "done\n",
      "11.041070938110352\n",
      "done\n",
      "10.742156982421875\n",
      "done\n",
      "10.45304274559021\n",
      "done\n",
      "9.391588926315308\n",
      "done\n",
      "8.93793511390686\n",
      "done\n",
      "8.668960809707642\n",
      "done\n",
      "9.174504041671753\n",
      "done\n",
      "10.38405466079712\n",
      "done\n",
      "10.32744550704956\n",
      "done\n",
      "10.368625402450562\n",
      "done\n",
      "10.811190128326416\n",
      "done\n",
      "11.98306393623352\n",
      "done\n",
      "11.32827615737915\n",
      "done\n",
      "11.23373532295227\n",
      "done\n",
      "11.73703670501709\n",
      "done\n",
      "11.889053583145142\n",
      "done\n",
      "11.493577003479004\n",
      "done\n",
      "11.505966424942017\n",
      "done\n",
      "11.435509204864502\n",
      "done\n",
      "10.984803676605225\n",
      "done\n",
      "10.635837316513062\n",
      "done\n",
      "9.648072957992554\n",
      "done\n",
      "9.375365257263184\n",
      "[False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False]\n"
     ]
    }
   ],
   "source": [
    "flags = []\n",
    "from time import time\n",
    "\n",
    "with h5py.File('./data/11y1burn6hres45mstep_mini/chan81_ncdf4.nc', 'r') as raw:\n",
    "    for i in range(81):\n",
    "        t = time()\n",
    "        flag = np.isnan(raw['Transformed'][:,i,:,:]).any()\n",
    "        flags.append(flag)\n",
    "        print(\"done\")\n",
    "        print(time()-t)\n",
    "print(flags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a0e5e4b1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "channels info in order: abbrev, name, levels, puma code, unit\n",
      "d transformation meta statistic by hPa levels 100 to 1000\n",
      "dimension info\n",
      "hus transformation meta statistic by hPa levels 100 to 1000\n",
      "order of atmospheric level in pressure: from space to surface\n",
      "ps transformation meta statistic by hPa levels 100 to 1000\n",
      "ta transformation meta statistic by hPa levels 100 to 1000\n",
      "ua transformation meta statistic by hPa levels 100 to 1000\n",
      "va transformation meta statistic by hPa levels 100 to 1000\n",
      "zeta transformation meta statistic by hPa levels 100 to 1000\n",
      "zg transformation meta statistic by hPa levels 100 to 1000\n"
     ]
    }
   ],
   "source": [
    "with h5py.File('./data/11y1burn6hres45mstep_mini/chan81_ncdf4.nc', 'a') as raw:\n",
    "    [print(k) for k in raw['Transformed'].attrs]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6ac499",
   "metadata": {},
   "source": [
    "# Garbage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b408d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('./data/11y1burn6hres45mstep_mini/chan81_ncdf4.nc', 'r') as raw:\n",
    "    descr = [          \n",
    "         ('ta',  'air_temperature',       '10','130','K'),\n",
    "         ('ua',  'eastward_wind',         '10','131','m s-1'),\n",
    "         ('va',  'northward_wind',        '10','132','m s-1'),\n",
    "         ('hus', 'specific_humidity',     '10','133','kg/kg'),\n",
    "         ('ps',  'surface_air_pressure',  '1 ','134','hPa'),\n",
    "         ('wap',  'vertical_air_velocity', '10','135','Pa s-1'),\n",
    "         ('zeta','atm_relative_vorticity','10','138','s-1'),\n",
    "         ('d',   'divergence of wind',    '10','155','s-1'),\n",
    "         ('zg',  'geopotential_height',   '10','156','m'),\n",
    "    ]\n",
    "    for k,_,lv,_,_ in descr:\n",
    "        d = raw[k][:]\n",
    "        if k == 'ps':\n",
    "            d = np.expand_dims(d,1)\n",
    "        transformed, attrs = transforms[k][0](d[:])\n",
    "        print(k,attrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "925da746",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = np.zeros((2,2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84957d81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1, 2, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.expand_dims(p,1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "448969e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  1.        ,  1.        , ...,  1.        ,\n",
       "         1.        ,  1.        ],\n",
       "       [ 0.93548387,  0.93548387,  0.93548387, ...,  0.93548387,\n",
       "         0.93548387,  0.93548387],\n",
       "       [ 0.87096774,  0.87096774,  0.87096774, ...,  0.87096774,\n",
       "         0.87096774,  0.87096774],\n",
       "       ...,\n",
       "       [-0.87096774, -0.87096774, -0.87096774, ..., -0.87096774,\n",
       "        -0.87096774, -0.87096774],\n",
       "       [-0.93548387, -0.93548387, -0.93548387, ..., -0.93548387,\n",
       "        -0.93548387, -0.93548387],\n",
       "       [-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "        -1.        , -1.        ]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.tile(np.linspace(1,-1,32),(64,1)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a891ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File('TransformedDS.hdf5','a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "49af5e37",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if 'LatitudeMap' not in f:\n",
    "    f.create_dataset(\"LatitudeMap\",(32,64),dtype = 'f4')\n",
    "    f['LatitudeMap'] = np.tile(\n",
    "        np.linspace(-1, 1, num=32, endpoint=True, retstep=False, dtype='f4', axis=0),\n",
    "        (64,1)\n",
    "    ).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6a1bbf5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = h5py.File('./data/11y1burn6hres45mstep_mini/chan81_ncdf4.nc','r')\n",
    "#f.create_dataset(\"TransformedData\",(14608,81, 32, 64),dtype = 'f4')\n",
    "if \"TransformedData\" not in f:\n",
    "    f.create_dataset(\"TransformedData\",(14608,81, 32, 64),dtype = 'f4')\n",
    "    \n",
    "raw.close()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
